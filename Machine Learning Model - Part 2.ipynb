{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f50ec2",
   "metadata": {},
   "source": [
    "# Part 2 - Machine Learning for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8993b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy sklearn imblearn matplotlib nltk seaborn torch torchvision torchaudio tqdm openai plotly xgboost transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8075d50",
   "metadata": {},
   "source": [
    "### Fine-Tuning BERT\n",
    "\n",
    "Initially, we assumed that the bulk of relevant information was contained in the textual columns, leading us to explore transformer-based models like BERT, Googleâ€™s pre-trained NLP model.\n",
    "\n",
    "We fine-tuned BERT by unfreezing the last two layer blocks (out of a total of 32 layers) using the code in bert.py. Training ran smoothly with the required dependencies and sufficient memory for the specified BATCH_SIZE.\n",
    "\n",
    "Surprisingly, we found that XGBoost outperformed BERT. Although transformer models like BERT are expected to capture complex contextual relationships in text, XGBoost likely benefited from information outside the text data, giving it a notable edge.\n",
    "\n",
    "Below are the results from the first three epochs using our latest configuration:\n",
    "\n",
    "![BERT Training.](images/bert_training.png) With appropriate learning\n",
    "rate decay, the highest validation epoch accuracy I've seen was 94.5. I\n",
    "decided to drop the model and use trees based models for the final\n",
    "prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef08a1",
   "metadata": {},
   "source": [
    "### Pre-processing Stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184c644e",
   "metadata": {},
   "source": [
    "The following classes will be used to preprocess data within an imblearn pipeline before training machine learning models.\n",
    "\n",
    "-   **FillNA** - Filling all NA's with the string \"na\".\n",
    "\n",
    "-   **MergeWithFoodNutrients** - Merge the food dataframes with the\n",
    "    nutriests & food_nutrients merged dataframe, as in Part 1.\n",
    "\n",
    "    -   *nutrient_min_freq* - Minimum frequency for the nutrient to\n",
    "        found in different snacks, else column will be dropped.\n",
    "\n",
    "-   **DropColumns**\n",
    "\n",
    "-   **NaiveBayesScores** - Adds the Naive Bayes scores for each category\n",
    "    (total 6), or the count vectorization without applying the Naive\n",
    "    Bayes model, for a given textual column.\n",
    "\n",
    "    -   *colname* - The required textual column.\n",
    "\n",
    "    -   *preprocess_func* - preprocessing func to apply over the textual\n",
    "        column before doing anything else.\n",
    "\n",
    "        *vectorizer_kwgs* - kwargs for the vectorizer (as in\n",
    "        sklearn.feature_extraction.CountVectorizer & TfidfVectorizer.\n",
    "\n",
    "    -   *mode* - \"scores\" for the Naive Bayes scores, or \"count\" for\n",
    "        vectorize to textual column without applying Naive Bayes. The\n",
    "        latter may result in adding a significant number of columns to\n",
    "        the dataset (one for each unique word/n-gram). I'll be\n",
    "        controlling the number of column by tuning the vectorizer\n",
    "        kwargs, such as removing stop-words, stripping accent into ascii\n",
    "        letters, including only tokens with `min_df` occurrences.\n",
    "\n",
    "    -   *use_tfidf* - True for TfidfVectorizer, False for\n",
    "        CountVectorizer (empirically works better).\n",
    "\n",
    "-   **CleanAndListifyIngredients** - As described in Part 1. removes\n",
    "    text inside () and [], some regexing for cleaning the ingredients.\n",
    "    Ingredient containing more than a single word, will be spaced by an\n",
    "    underscore, and different ingredients will be separated by a single\n",
    "    space \" \".\n",
    "\n",
    "    -   *keep_top_n* - Keep only first n ingredients.\n",
    "\n",
    "-   **StandardScale** - Standard scaler wrapper, to bypass the 'idx'\n",
    "    column. Not important for tree based models.\n",
    "\n",
    "-   **StemDescription** - Omitting description words suffixes, as in\n",
    "    `nltk.stem.snowball.SnowballStemmer` .\n",
    "\n",
    "        Few Rules:\n",
    "        ILY  -----> ILI\n",
    "        LY   -----> Nil\n",
    "        SS   -----> SS\n",
    "        S    -----> Nil\n",
    "        ED   -----> E,Nil\n",
    "\n",
    "-   **AddImportantTokens** - Not in use. Adding only tokens passing some\n",
    "    importance threshold.\n",
    "\n",
    "-   **AddCategoryTokensAppearance** - Not in use. Adding a column for\n",
    "    each word in the categories, if they're found in a textual column.\n",
    "\n",
    "After many trials, we decided to build the following pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c480d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.preprocess import (\n",
    "    FillNA,\n",
    "    MergeWithFoodNutrients,\n",
    "    CleanAndListifyIngredients,\n",
    "    NaiveBayesScores,\n",
    "    LogTransformation,\n",
    "    DropColumns,\n",
    "    StemDescription,\n",
    ")\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "steps = [\n",
    "    FillNA(),\n",
    "    MergeWithFoodNutrients(nutrient_min_freq=2),\n",
    "    CleanAndListifyIngredients(),\n",
    "    StemDescription(),\n",
    "    NaiveBayesScores(colname=\"brand\", preprocess_func=lambda x: x.replace(\" \", \"\"),\n",
    "            vectorizer_kwgs=dict(\n",
    "            stop_words=\"english\", ngram_range=(1, 6), strip_accents=\"unicode\", min_df=20\n",
    "        ),\n",
    "        mode=\"count\",\n",
    "        use_tfidf=False,\n",
    "    ),\n",
    "    NaiveBayesScores(\n",
    "        colname=\"description\",\n",
    "        vectorizer_kwgs=dict(\n",
    "            stop_words=\"english\", ngram_range=(1, 6), strip_accents=\"unicode\", min_df=50\n",
    "        ),\n",
    "        mode=\"count\",\n",
    "        use_tfidf=False,\n",
    "    ),\n",
    "    NaiveBayesScores(\n",
    "        colname=\"ingredients\",\n",
    "        vectorizer_kwgs=dict(\n",
    "            stop_words=\"english\", ngram_range=(1, 6), strip_accents=\"unicode\", min_df=50, max_df=0.6\n",
    "        ),\n",
    "        mode=\"count\",\n",
    "        use_tfidf=False,\n",
    "    ),\n",
    "    NaiveBayesScores(\n",
    "        colname=\"household_serving_fulltext\",\n",
    "        vectorizer_kwgs=dict(stop_words=\"english\", ngram_range=(1, 6), strip_accents=\"unicode\", min_df=50),\n",
    "        mode=\"count\",\n",
    "        use_tfidf=False,\n",
    "    ),\n",
    "    LogTransformation(columns=[\"serving_size\"]),\n",
    "    DropColumns(columns=[\"serving_size_unit\"]),\n",
    "]\n",
    "\n",
    "\n",
    "pipe = Pipeline([(f\"{i}\", step) for i, step in enumerate(steps)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0cbc2f",
   "metadata": {},
   "source": [
    "This pipeline produces a wide matrix (about 2000 columns) because we set mode=\"count\" in NaiveBayesScores, creating a count column for each token with a frequency above min_df.\n",
    "\n",
    "In our exploration, we discovered that chocolate is a challenging category to predict and is also less frequent than others. We attempted to address this with SMOTE, but the improvement was minimal. This may be because we applied oversampling early in the process while still extracting featuresâ€”applying it now could potentially yield better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e3d5c",
   "metadata": {},
   "source": [
    "### ResNet18 Score Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552399f5",
   "metadata": {},
   "source": [
    "\\*\\* Code is based on\n",
    "<https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a890b",
   "metadata": {},
   "source": [
    "Weâ€™ll begin by leveraging the images in the dataset. Integrating the images with structured data wasnâ€™t straightforward, so I experimented with two methods, using a ResNet18 model. All model weights were frozen except for the last layer or a few final layers. The model was trained for 100 epochs with a learning rate of 0.001, decaying by a factor of 0.1 every 7 epochs.\n",
    "\n",
    "The two approaches tested were:\n",
    "\n",
    "1. Fine-tuning ResNet18 by replacing the last layer with 6 output classes.\n",
    "\n",
    "2. Fine-tuning ResNet18 by replacing the last layer with \n",
    "ð‘›\n",
    "n outputs (where \n",
    "6\n",
    "â‰¤\n",
    "ð‘›\n",
    "â‰¤\n",
    "256\n",
    "), then concatenating the \"last layer\" output with structured features and adding [FC -> BN -> ReLU] blocks, ending with 6 output scores.\n",
    "\n",
    "![2nd Approach Illustration.](images/images_net.png)\n",
    "\n",
    "The code is in helpers/resnet.py, although itâ€™s been modified frequently. The ResNet18ForSnacks class represents the latest architecture I used.\n",
    "\n",
    "Now, letâ€™s see how well we can predict the class using the first approach (images only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e045a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "rn18_train = pd.read_csv(f\"data/_resnet18_train_features_fine_tuned.csv\", index_col=0)\n",
    "\n",
    "y = rn18_train['y']\n",
    "y_pred = rn18_train.drop(columns='y').idxmax(axis=1).astype('int')\n",
    "print(f'accuracy: {round(accuracy_score(y, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6396d",
   "metadata": {},
   "source": [
    "Not too bad, though not particularly strong either. Weâ€™ll include these scores as six new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eaeefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_train_val_test():\n",
    "    food_train = pd.read_csv(\"data/food_train.csv\")\n",
    "    \n",
    "    features_df = food_train.drop(\"category\", axis=1)\n",
    "    labels_df = food_train[\"category\"]\n",
    "    \n",
    "    image_scores_df = (\n",
    "        pd.read_csv(f\"data/resnet18_food_train_features_fine_tuned.csv\", index_col=0)\n",
    "        .set_index(food_train.index)\n",
    "        .drop(columns=[\"y\"])\n",
    "        .add_prefix(\"image_scores_\")\n",
    "    )\n",
    "    \n",
    "    features_df = pd.concat([features_df, image_scores_df], axis=1)\n",
    "    \n",
    "    \n",
    "    X_train, X_val_test, y_train, y_val_test = train_test_split(\n",
    "        features_df, labels_df, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    \n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_val_test, y_val_test, test_size=0.25, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17ef27",
   "metadata": {},
   "source": [
    "In the second approach, I couldnâ€™t surpass 0.92 accuracy. Given that the data is primarily structured after preprocessing, I opted to rely on tree ensemble methods rather than a large unified network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c39be6",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set():\n",
    "    X = pd.read_csv(\"data/food_test.csv\")\n",
    "    \n",
    "    image_scores_df = (\n",
    "        pd.read_csv(f\"data/resnet18_food_test_features_fine_tuned.csv\", index_col=0)\n",
    "        .set_index(X.index)\n",
    "        .add_prefix(\"image_scores_\")\n",
    "    )\n",
    "    \n",
    "    X = pd.concat([X, image_scores_df], axis=1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def save_predictions(model, path):\n",
    "    labels = [\n",
    "      \"cakes_cupcakes_snack_cakes\",\n",
    "      \"candy\",\n",
    "      \"chips_pretzels_snacks\",\n",
    "      \"chocolate\",\n",
    "      \"cookies_biscuits\",\n",
    "      \"popcorn_peanuts_seeds_related_snacks\"\n",
    "    ]\n",
    "    \n",
    "    X = get_test_set()\n",
    "    X = pipe.transform(X)\n",
    "    \n",
    "    X['pred_cat'] = model.predict(X)\n",
    "    X['pred_cat'] = X['pred_cat'].apply(lambda x: x if isinstance(x, str) else labels[x])\n",
    "    \n",
    "    X[['idx', 'pred_cat']].to_csv(path, index=False)\n",
    "    X.drop(columns=['pred_cat'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64db64",
   "metadata": {},
   "source": [
    "##### The models we picked are the following:\n",
    "\n",
    "-   Random Forest Classifier\n",
    "\n",
    "-   XGBoost\n",
    "\n",
    "-   Ensemble of XGBoosts\n",
    "\n",
    "All models will use the pipeline above for preprocessing.\n",
    "\n",
    "For cross-validation, X_train is used for training and X_val for validation. In the final model training, weâ€™ll combine X_train and X_val for training and use X_test to benchmark performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083fc878",
   "metadata": {},
   "source": [
    "## 1st Model - Random Forest Classifier\n",
    "\n",
    "Random Forest was chosen for its robustness and ability to capture complex relationships through aggregated decision trees, making it well-suited for tasks requiring feature importance insights and strong generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = get_train_val_test()\n",
    "X = pd.concat([X_val, X_train], axis=0)\n",
    "y = pd.concat([y_val, y_train], axis=0)\n",
    "X = pipe.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import dump\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  # Number of trees in the forest\n",
    "    'criterion': ['gini', 'entropy'],           # Split criterion\n",
    "    'max_depth': [None, 10, 20, 30, 40],        # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],            # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],              # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False],                 # Whether bootstrap samples are used\n",
    "    'random_state': [42]                        # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Create RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,            # Number of parameter settings that are sampled\n",
    "    scoring='accuracy',   # Scoring metric for evaluation\n",
    "    cv=5,                 # Cross-validation folds\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV to your data\n",
    "random_search.fit(X, y)\n",
    "\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "dump(best_model, 'checkpoints/rf/best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198ccaa",
   "metadata": {},
   "source": [
    "###### Benchmarking over test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "X_test = pipe.transform(X_test)\n",
    "\n",
    "model = load('checkpoints/rf/best_model.joblib')\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cffe1a7",
   "metadata": {},
   "source": [
    "#### Saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c199f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_test_set()\n",
    "X = pipe.transform(X)\n",
    "\n",
    "save_predictions(model, 'predictions/model01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee551e8",
   "metadata": {},
   "source": [
    "## 2nd Model - XGBoost\n",
    "\n",
    "XGBoost is selected for its efficient gradient boosting framework that\n",
    "excels in structured data scenarios, such as our case.\n",
    "\n",
    "Messing with structured data without trying the king of Kaggle in at\n",
    "least one of the trials is a shame. Again, starting with random search\n",
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7411699",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = {\n",
    "    \"cakes_cupcakes_snack_cakes\": 0,\n",
    "    \"candy\": 1,\n",
    "    \"chips_pretzels_snacks\": 2,\n",
    "    \"chocolate\": 3,\n",
    "    \"cookies_biscuits\": 4,\n",
    "    \"popcorn_peanuts_seeds_related_snacks\": 5,\n",
    "}\n",
    "y = y.apply(lambda x: dmap[x])\n",
    "y_test = y_test.apply(lambda x: dmap[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b052b",
   "metadata": {},
   "source": [
    "Random Search CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 6, 7, 8],\n",
    "    'min_child_weight': [1, 2, 4],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 0.3],\n",
    "    'reg_lambda': [0, 0.1, 0.3],\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(objective='multi:softmax', num_class=6, random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    n_jobs=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X, y)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "\n",
    "best_model.save_model('checkpoints/xgb/xgb.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fa1ab4",
   "metadata": {},
   "source": [
    "Benchmarking over test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73292efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "best_xgb = XGBClassifier()\n",
    "best_xgb.load_model('checkpoints/xgb/xgb.model')\n",
    "\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4843a",
   "metadata": {},
   "source": [
    "Saving predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb4b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(best_xgb, 'predictions/model02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84941962",
   "metadata": {},
   "source": [
    "XGBoost outperformed Random Forest, leading us to choose an ensemble of XGBoost models with the optimal parameters from cross-validation as our final model. This ensemble aims to reduce the variance of a single model, enhancing prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47129cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "best_xgb = XGBClassifier()\n",
    "best_xgb.load_model('checkpoints/xgb/xgb.model') # best xgb model\n",
    "\n",
    "ensemble = BaggingClassifier(best_xgb, n_estimators=20, verbose=2, n_jobs=2, random_state=42)\n",
    "ensemble.fit(X, y)\n",
    "\n",
    "\n",
    "dump(ensemble, 'checkpoints/xgb_ensemble/ensemble.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa98a9",
   "metadata": {},
   "source": [
    "Benchmarking over test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "ensemble = load('checkpoints/xgb_ensemble/ensemble.joblib')\n",
    "ensemble.set_params(n_jobs=1) # to avoid SEGFAULT in rstudio\n",
    "\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Saving predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(ensemble, 'predictions/model03.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4897a2",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "- **XGBoost outperformed Random Forest** with identical settings.\n",
    "- **Deep models** like BERT performed worse than XGBoost, considering our specific use cases.\n",
    "- **Ensembles donâ€™t always ensure better performance** on the test set.\n",
    "- **Feature extraction** is crucial for strong performance, regardless of the model choice.\n",
    "- **Sklearn, pandas, and PyTorch** are robust frameworks for machine learning.\n",
    "- **High-feature models** (with features almost 10% of sample size) performed well and were less prone to overfitting than expected.\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for reading!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
